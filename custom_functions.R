#Custom Functions

###load or install packages
ipak <- function (pkg) {
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if (length(new.pkg)) 
    install.packages(new.pkg, dependencies = TRUE)
  sapply(pkg, require, character.only = TRUE)
}


#This is to clean data and make new variables for Study 1
clean_data<-function(RawData){
  
  #This is filtering out the fake data generated by qualtrics, as well as tests that we did for piloting.
  # TEST_data <- filter(RawData, !DistributionChannel== 'test')
  TEST_data <- filter(RawData, !Field== 'TEST')
  
  #This is transforming the warmth variables into a 5 point scale 
  TEST_data <- TEST_data %>% 
    mutate(FriendlyR = ((Friendly-1)*(4/6)+1))
  
  TEST_data <- TEST_data %>% 
    mutate(KindR = ((Kind-1)*(4/6)+1))
  
  TEST_data <- TEST_data %>% 
    mutate(LikableR = ((Likable-1)*(4/6)+1))
  
  TEST_data <- TEST_data %>% 
    mutate(NiceR = ((Nice-1)*(4/6)+1))
  
  #To get an average for warmth
  TEST_data <- TEST_data %>% 
    mutate(WarmthT =(FriendlyR+KindR+LikableR+NiceR)/4 )
  
  #To log transform Years
  TEST_data <- TEST_data %>% 
    mutate(Yearslog =log(Years))
  
  #This is transforming the comptenence variables into a 5 point scale.
  
  TEST_data <- TEST_data %>% 
    mutate(CapableR = ((Capable-1)*(4/6)+1))
  
  TEST_data <- TEST_data %>% 
    mutate(CompetentR = ((Competent	-1)*(4/6)+1))
  
  TEST_data <- TEST_data %>% 
    mutate(EfficientR = ((Efficient-1)*(4/6)+1))
  
  TEST_data <- TEST_data %>% 
    mutate(SkillfulR = ((Skillful-1)*(4/6)+1))
  
  #To get an average for Competence
  TEST_data <- TEST_data %>% 
    mutate(CompetenceT =(CapableR+CompetentR+EfficientR+SkillfulR)/4 )
  
  #To get an average for Hierarchy_ZeroSum
  TEST_data <- TEST_data %>% 
    mutate(Hierarchy_ZeroSum =((Hierarchy+Junior+Norms.Prestige+	Norms.Less.well.know +Stealing.Ideas+	Zero.Sum+	Seminar	+Conferences)/8))
  
  #To get an average for Cooperate_Collaborate
  TEST_data <- TEST_data %>% 
    mutate(Cooperate_Collaborate2 =((Collaborate+Cooperate)/2))
  
  #This is transforming the the Cooperation Scale
  TEST_data <- TEST_data %>% 
    mutate(Cooperate_Collaborate = (6-(Cooperate_Collaborate2)))
  
  # #This is making two new data frames, one that has each of the values
  # TEST_data_hiercomp<- dplyr::select(TEST_data, c('Hierarchy':'Cooperate'))
  # TEST_data_warmthcompete<-dplyr::select(TEST_data,c('Hierarchy':'Cooperate', 'FriendlyR':'NiceR','CapableR':'SkillfulR'))
  
  # #Remove rows with missing values and keep only complete cases
  # TEST_data_hiercomp_cut=TEST_data_hiercomp[complete.cases(TEST_data_hiercomp), ]
  # TEST_data_warmthcompete=TEST_data_warmthcompete[complete.cases(TEST_data_warmthcompete), ]
  
  #This is making data frames by factor to calculate reliability in scales later
  #These are the factors that fall out of exploratory factor analysis
  # TEST_data_Hierarchy_ZeroSum<-dplyr::select(TEST_data_hiercomp_cut,c('Hierarchy':'Zero.Sum'))
  # TEST_data_Cooperate_Collaborate<-dplyr::select(TEST_data_hiercomp_cut,c('Collaborate':'Cooperate'))
  # TEST_data_warmth<-dplyr::select(TEST_data_warmthcompete,c('FriendlyR':'NiceR'))
  # TEST_data_competence<-dplyr::select(TEST_data_warmthcompete,c('CapableR':'SkillfulR'))
  
  #These our our pre-registered factors
  # TEST_data_prehier<-dplyr::select(TEST_data_hiercomp_cut,c('Hierarchy':'Norms.Less.well.know','Seminar':'Conferences'))
  # TEST_data_precom<-dplyr::select(TEST_data_hiercomp_cut,c('Stealing.Ideas':'Cooperate'))
  
  #This is to remove the NAs from the data frames
#   TEST_data_Hierarchy_ZeroSum=TEST_data_Hierarchy_ZeroSum[complete.cases(TEST_data_Hierarchy_ZeroSum), ]
#   
#   TEST_data_Cooperate_Collaborate=TEST_data_Cooperate_Collaborate[complete.cases(TEST_data_Cooperate_Collaborate), ]
#   
#   TEST_data_precom=TEST_data_precom[complete.cases(TEST_data_precom), ]
#   
#   TEST_data_prehier=TEST_data_prehier[complete.cases(TEST_data_prehier), ]
#   
# }

}


#This is to clean data and make new variables for Studies 2 and 3
clean_data2<-function(RawData){

  #Filterout the fake data generated by qualtrics, as well as tests that we did for piloting.
  TEST_data <- filter(RawData, !Field== 'TEST')
  
  #Change all values that say 666 to NA (NA was coded as 666 in Qualtrics)
  TEST_data[ TEST_data == '666'] <- NA
  
  #Change columns to numeric
  TEST_data[21:65,] = lapply(TEST_data[21:65,], FUN = function(y){as.numeric(y)})
  
  #Change the Years in field into a log scale
  TEST_data$Years<-as.numeric(TEST_data$Years)
  TEST_data<-TEST_data %>% mutate(LogYears =log(Years))
  
  #Get an average for the Hierarchy and Zero Sum factor
  TEST_data <- TEST_data %>% 
    mutate(Hierarchy_ZeroSum =((Hierarchy+Junior+Norms.Prestige+Norms.Less.well.know +Stealing.Ideas+	Zero.Sum+	Seminar+Conferences)/8))
  
  #Get an average for Cooperate_Collaborate
  TEST_data <- TEST_data %>% 
    mutate(Cooperate_Collaborate =((Collaborate+Cooperate)/2))
  
  #Transform the the Cooperation Scale so its the same direction as the hierarchy factor
  TEST_data <- TEST_data %>% 
    mutate(Cooperate_Collaborate2 = (6-(Cooperate_Collaborate)))
  
  #Get an average for plans to share materials
  TEST_data <- TEST_data %>% 
    mutate(plan_materials =((plan_data+plan_code+plan_instrument)/3))
  
  TEST_data$plan_materials<-as.integer(cut(TEST_data$plan_materials, breaks = c(0,1, 2, 3, 4,5,Inf)))
  
  #This is to make a data frame that has just the reasons
  TEST_data_reasons<- dplyr::select(TEST_data, c('other_MS_require':'self_materials_lab'))
  TEST_data_reasons_cut=TEST_data_reasons[complete.cases(TEST_data_reasons), ]
  
  #This is making data frames by factor to calculate reliability in scales later
  
  #These are the factors that fall out of the factor analysis
  TEST_data_Hierarchy_ZeroSum<-dplyr::select(TEST_data,c('Hierarchy':'Conferences'))
  TEST_data_Cooperate_Collaborate<-dplyr::select(TEST_data,c('Collaborate':'Cooperate'))
  
  #This is to remove the NAs from the data frames
  TEST_data_Hierarchy_ZeroSum=TEST_data_Hierarchy_ZeroSum[complete.cases(TEST_data_Hierarchy_ZeroSum), ]
  
  TEST_data_Cooperate_Collaborate=TEST_data_Cooperate_Collaborate[complete.cases(TEST_data_Cooperate_Collaborate), ]
  
  #Making factors for reasons based on factor analysis.
  
  #This is making a new data frames that also has plans
  TEST_data_withplans<- dplyr::select(TEST_data, c('Hierarchy':'Cooperate','plan_materials','plan_MS','self_MS_prestige','self_MS_cooper', 'self_materials_prestige','self_materials_cooper')) 
  
  #Remove rows with missing values and keep only complete cases
  TEST_data_withplans_cut=TEST_data_withplans[complete.cases(TEST_data_withplans), ]
  
  #Making new variables by combinding the facts that loaded onto one another in people's answers about reasons for sharing materials and manuscripts. 
  
  #reason_other_coop combines all the pro-social motives of others. 
  TEST_data <- TEST_data %>% 
    mutate(reason_other_coop=(other_MS_cooper+other_materials_cooper)/2)
  
  #reason_self_coop combines all the pro-social motives of others. 
  TEST_data <- TEST_data %>% 
    mutate(reason_self_coop=((self_MS_cooper+self_materials_cooper)/2))
  
  TEST_data <- TEST_data %>% 
    mutate(reason_prestige=((self_MS_prestige+self_materials_prestige+other_MS_prestige+other_materials_prestige)/4))
  
  TEST_data <- TEST_data %>% 
    mutate(reason_require=((self_MS_require+other_MS_require+self_materials_require+other_materials_require)/4))
  
  TEST_data <- TEST_data %>% 
    mutate(reason_lab=((self_MS_lab+other_MS_lab+self_materials_lab+other_materials_lab)/4))
  
  TEST_data <- TEST_data %>% 
    mutate(reason_public=((self_MS_public+other_MS_public+self_materials_public+other_materials_public)/4))
}

###### Histogram ####

hist_functionc<-function(x,z,graphtitle){

p<-dplyr::filter(x, z>1)


#To log transform z

g<-ggplot(x, aes(x =z)) +                           
  geom_histogram(binwidth=(1),color='black',fill='skyblue') +
  labs (x=graphtitle)

z2<-g+theme_minimal_hgrid(12)+theme(axis.title = element_text(size = 8))

z2
}

## Word Cloud

wordcloudc<-function(x){
  
  wordcloud(words = x, min.freq = 2,max.words=200, random.order=FALSE, rot.per=0, colors=brewer.pal(2, "Dark2"),size=1)
}

## Make Scree Plot



factorC<-function(data,nfact) {

#Create the correlation matrix from bfi_data
bfi_cor <- cor(data)

#Factor analysis of the data
factors_data <- fa(r = bfi_cor, nfactors = nfact)
#Getting the factor loadings and model analysis

fafitfree <- fa(data,nfactors = nfact, rotate = "none")
n_factors <- length(fafitfree$e.values)
scree     <- data.frame(
  Factor_n =  as.factor(1:n_factors), 
  Eigenvalue = fafitfree$e.values)

p<-ggplot(scree, aes(x = Factor_n, y = Eigenvalue, group = 1)) + 
  geom_point() + geom_line() +
  xlab("Number of factors") +
  ylab("Initial eigenvalue") +
  labs( title = "Scree Plot", 
        subtitle = "(Based on the unreduced correlation matrix)")
fa.diagram(factors_data)
p
}

#### https://sakaluk.wordpress.com/2016/05/26/11-make-it-pretty-scree-plots-and-parallel-analysis-using-psych-and-ggplot2/

prettyscreeplot<-function(data){

parallel <- fa.parallel(data,plot=FALSE)
#Create data frame &amp;amp;amp;amp;amp;quot;obs&amp;amp;amp;amp;amp;quot; from observed eigenvalue data
obs<- data.frame(parallel$fa.values)
obs$type <- c('Observed Data')
obs$num <- c(row.names(obs))
obs$num <- as.numeric(obs$num)
colnames(obs) <- c('eigenvalue', 'type', 'num')

#Calculate quantiles for eigenvalues, but only store those from simulated CF model in percentile1
percentile <- apply(parallel$values,2,function(x) quantile(x,.95))
min <- as.numeric(nrow(obs))
min <- (4*min) - (min-1)
max <- as.numeric(nrow(obs))
max <- 4*max
percentile1 <- percentile[min:max]

#Calculate quantiles for eigenvalues, but only store those from simulated CF model in percentile1
percentile <- apply(parallel$values,2,function(x) quantile(x,.95))
min <- as.numeric(nrow(obs))
min <- (4*min) - (min-1)
max <- as.numeric(nrow(obs))
max <- 4*max
percentile1 = percentile[min:max]

#Create data frame called &amp;amp;amp;amp;amp;quot;sim&amp;amp;amp;amp;amp;quot; with simulated eigenvalue data
sim <- data.frame(percentile1)
sim$type <- c('Simulated Data (95th %ile)')
sim$num <- c(row.names(obs))
sim$num <- as.numeric(sim$num)
colnames(sim) <- c('eigenvalue', 'type', 'num')

#Merge the two data frames (obs and sim) together into data frame called eigendat
eigendat <- rbind(obs,sim)

apatheme<-theme_bw()+
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(),
        panel.border = element_blank(),
        text=element_text(family='Arial'),
        legend.title=element_blank(),
        legend.position=c(.7,.8),
        axis.line.x = element_line(color='black'),
        axis.line.y = element_line(color='black'))


#Use data from eigendat. Map number of factors to x-axis, eigenvalue to y-axis, and give different data point shapes depending on whether eigenvalue is observed or simulated
t <- ggplot(eigendat, aes(x=num, y=eigenvalue, shape=type)) +
  #Add lines connecting data points
  geom_line()+
  #Add the data points.
  geom_point(size=4)+
  #Label the y-axis 'Eigenvalue'
  scale_y_continuous(name='Eigenvalue')+
  #Label the x-axis 'Factor Number', and ensure that it ranges from 1-max # of factors, increasing by one with each 'tick' mark.
  scale_x_continuous(name='Factor Number', breaks=min(eigendat$num):max(eigendat$num))+
  #Manually specify the different shapes to use for actual and simulated data, in this case, white and black circles.
  scale_shape_manual(values=c(16,1)) +
  #Add vertical line indicating parallel analysis suggested max # of factors to retain
  geom_vline(xintercept = parallel$nfact, linetype = 'dashed')+
  #Apply our apa-formatting theme
  apatheme
#Call the plot. Looks pretty!
t
}

#### ROPE Analysis ####

ROPEC<-function(model,title) {

percentage_in_rope1 <- rope(model, range=c(-0.1,0.1),ci=1)
percentage_in_rope1

percentage_in_rope1$ROPE_Percentage<-(percentage_in_rope1$ROPE_Percentage)*100
# 
table3<-(percentage_in_rope1) %>%
  gt() %>%
  tab_header(
    title = md("**ROPE Percentages**"),
    subtitle=md(title)
  )%>%
  cols_hide(columns=c('Effects','CI','Component',"ROPE_low","ROPE_high"))

table3
}


